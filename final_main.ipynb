{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: data/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Ensure the directories for saving data exist\n",
    "def create_directories():\n",
    "    if not os.path.exists('data/'):\n",
    "        os.makedirs('data/')\n",
    "        print(\"Created directory: data/\")\n",
    "    if not os.path.exists('models/'):\n",
    "        os.makedirs('models/')\n",
    "        print(\"Created directory: models/\")\n",
    "\n",
    "create_directories()  # Create the necessary directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nduration: continuous.\\nprotocol_type: symbolic.\\nservice: symbolic.\\nflag: symbolic.\\nsrc_bytes: continuous.\\ndst_bytes: continuous.\\nland: symbolic.\\nwrong_fragment: continuous.\\nurgent: continuous.\\nhot: continuous.\\nnum_failed_logins: continuous.\\nlogged_in: symbolic.\\nnum_compromised: continuous.\\nroot_shell: continuous.\\nsu_attempted: continuous.\\nnum_root: continuous.\\nnum_file_creations: continuous.\\nnum_shells: continuous.\\nnum_access_files: continuous.\\nnum_outbound_cmds: continuous.\\nis_host_login: symbolic.\\nis_guest_login: symbolic.\\ncount: continuous.\\nsrv_count: continuous.\\nserror_rate: continuous.\\nsrv_serror_rate: continuous.\\nrerror_rate: continuous.\\nsrv_rerror_rate: continuous.\\nsame_srv_rate: continuous.\\ndiff_srv_rate: continuous.\\nsrv_diff_host_rate: continuous.\\ndst_host_count: continuous.\\ndst_host_srv_count: continuous.\\ndst_host_same_srv_rate: continuous.\\ndst_host_diff_srv_rate: continuous.\\ndst_host_same_src_port_rate: continuous.\\ndst_host_srv_diff_host_rate: continuous.\\ndst_host_serror_rate: continuous.\\ndst_host_srv_serror_rate: continuous.\\ndst_host_rerror_rate: continuous.\\ndst_host_srv_rerror_rate: continuous.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "duration: continuous.\n",
    "protocol_type: symbolic.\n",
    "service: symbolic.\n",
    "flag: symbolic.\n",
    "src_bytes: continuous.\n",
    "dst_bytes: continuous.\n",
    "land: symbolic.\n",
    "wrong_fragment: continuous.\n",
    "urgent: continuous.\n",
    "hot: continuous.\n",
    "num_failed_logins: continuous.\n",
    "logged_in: symbolic.\n",
    "num_compromised: continuous.\n",
    "root_shell: continuous.\n",
    "su_attempted: continuous.\n",
    "num_root: continuous.\n",
    "num_file_creations: continuous.\n",
    "num_shells: continuous.\n",
    "num_access_files: continuous.\n",
    "num_outbound_cmds: continuous.\n",
    "is_host_login: symbolic.\n",
    "is_guest_login: symbolic.\n",
    "count: continuous.\n",
    "srv_count: continuous.\n",
    "serror_rate: continuous.\n",
    "srv_serror_rate: continuous.\n",
    "rerror_rate: continuous.\n",
    "srv_rerror_rate: continuous.\n",
    "same_srv_rate: continuous.\n",
    "diff_srv_rate: continuous.\n",
    "srv_diff_host_rate: continuous.\n",
    "dst_host_count: continuous.\n",
    "dst_host_srv_count: continuous.\n",
    "dst_host_same_srv_rate: continuous.\n",
    "dst_host_diff_srv_rate: continuous.\n",
    "dst_host_same_src_port_rate: continuous.\n",
    "dst_host_srv_diff_host_rate: continuous.\n",
    "dst_host_serror_rate: continuous.\n",
    "dst_host_srv_serror_rate: continuous.\n",
    "dst_host_rerror_rate: continuous.\n",
    "dst_host_srv_rerror_rate: continuous.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_instance(instance, filename):\n",
    "    print(f\"Saving model instance: {filename}...\")\n",
    "    np.save(f'/home/dcll/hugging_face_learning/FineTuning_GPT2Model/gpt2_fine_tuned/model/ML-Project-Network_Intrusion_Detection/models/{filename}.npy', instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split dataset\n",
    "def load_and_split_data(df, target_column='outcome', test_size=0.2, random_state=42):\n",
    "    print(\"Loading and splitting the dataset...\")\n",
    "    X = df.drop(target_column, axis=1)  # Features\n",
    "    Y = df[target_column]  # Target\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state, stratify=Y)\n",
    "\n",
    "    # Save the split data\n",
    "    X_train.to_csv('data/X_train.csv', index=False)\n",
    "    X_test.to_csv('data/X_test.csv', index=False)\n",
    "    Y_train.to_csv('data/Y_train.csv', index=False)\n",
    "    Y_test.to_csv('data/Y_test.csv', index=False)\n",
    "\n",
    "    print(\"Data split into training and testing sets.\")\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "# Categorize the attack types into the 5 classes\n",
    "def categorize_attack_type(label):\n",
    "    if label in dos_attacks:\n",
    "        return 'DOS'\n",
    "    elif label in r2l_attacks:\n",
    "        return 'R2L'\n",
    "    elif label in u2r_attacks:\n",
    "        return 'U2R'\n",
    "    elif label in probe_attacks:\n",
    "        return 'probing'\n",
    "    else:\n",
    "        return 'normal'\n",
    "    \n",
    "\n",
    "# Example Usage\n",
    "df = pd.read_csv('data/data_with_column_names.csv')  # Replace with your actual dataset\n",
    "\n",
    "dos_attacks = ['smurf.', 'neptune.', 'back.', 'teardrop.', 'pod.', 'land.']\n",
    "r2l_attacks = ['warezclient.', 'guess_passwd.', 'imap.', 'warezmaster.', 'ftp_write.', 'phf.', 'spy.', 'multihop.']\n",
    "u2r_attacks = ['buffer_overflow.', 'loadmodule.', 'rootkit.', 'perl.']\n",
    "probe_attacks = ['satan.', 'ipsweep.', 'portsweep.', 'nmap.']\n",
    "df['outcome'] = df['outcome'].apply(categorize_attack_type)\n",
    "\n",
    "\n",
    "target_column = 'outcome'  # Define your target column\n",
    "# X_train, X_test, Y_train, Y_test = load_and_split_data(df, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding categorical features\n",
    "def one_hot_encode(X_train, X_test, categorical_columns):\n",
    "    print(\"One-hot encoding categorical features...\")\n",
    "    encoders = {}\n",
    "    X_train_encoded_list = []\n",
    "    X_test_encoded_list = []\n",
    "    feature_names = []\n",
    "\n",
    "    # Loop through each categorical column and apply OneHotEncoder\n",
    "    for col in categorical_columns:\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        \n",
    "        # Fit and transform the training data\n",
    "        X_train_col_encoded = encoder.fit_transform(X_train[[col]])\n",
    "        X_train_encoded_list.append(X_train_col_encoded)\n",
    "        \n",
    "        # Transform the test data\n",
    "        X_test_col_encoded = encoder.transform(X_test[[col]])\n",
    "        X_test_encoded_list.append(X_test_col_encoded)\n",
    "\n",
    "        # Store the encoder for potential future use\n",
    "        encoders[col] = encoder\n",
    "        \n",
    "        # Get feature names and add to the feature names list\n",
    "        feature_names.extend(encoder.get_feature_names_out([col]))\n",
    "\n",
    "        # save the encoder as encoder_{col}.npy\n",
    "        save_model_instance(encoder, f'encoder_{col}')\n",
    "    \n",
    "    # Concatenate the encoded columns into a single matrix\n",
    "    X_train_encoded = np.concatenate(X_train_encoded_list, axis=1)\n",
    "    X_test_encoded = np.concatenate(X_test_encoded_list, axis=1)\n",
    "\n",
    "    # Remove original categorical columns from X_train and X_test\n",
    "    X_train_remaining = X_train.drop(columns=categorical_columns)\n",
    "    X_test_remaining = X_test.drop(columns=categorical_columns)\n",
    "    \n",
    "    # Concatenate the remaining columns with the one-hot encoded columns\n",
    "    X_train_final = np.concatenate([X_train_remaining.values, X_train_encoded], axis=1)\n",
    "    X_test_final = np.concatenate([X_test_remaining.values, X_test_encoded], axis=1)\n",
    "    \n",
    "    # Ensure the directory exists before saving the files\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "\n",
    "    # Save the encoded data\n",
    "    np.save('data/X_train_encoded.npy', X_train_final)\n",
    "    np.save('data/X_test_encoded.npy', X_test_final)\n",
    "\n",
    "    print(\"Categorical features encoded and original columns removed.\")\n",
    "    return X_train_final, X_test_final, encoders\n",
    "\n",
    "# Example usage with specified categorical columns\n",
    "categorical_columns = ['protocol_type', 'service', 'flag']\n",
    "# X_train_encoded, X_test_encoded, encoders = one_hot_encode(X_train, X_test, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Robust Scaling\n",
    "def robust_scale(X_train, X_test):\n",
    "    print(\"Applying robust scaling...\")\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Save the scaled data\n",
    "    np.save('data/X_train_scaled.npy', X_train_scaled)\n",
    "    np.save('data/X_test_scaled.npy', X_test_scaled)\n",
    "\n",
    "    print(\"Data scaled using RobustScaler.\")\n",
    "\n",
    "    save_model_instance(scaler, 'scaler')\n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "# X_train_scaled, X_test_scaled, scaler = robust_scale(X_train_encoded, X_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.combine import SMOTEENN  # Import SMOTEENN\n",
    "\n",
    "# Apply SMOTEENN resampling\n",
    "def apply_smoteenn(X_train, Y_train):\n",
    "    print(\"Applying SMOTEENN for resampling...\")\n",
    "    \n",
    "    # Initialize SMOTEENN with a suitable k_neighbors\n",
    "    smote_enn = SMOTEENN(sampling_strategy='auto', random_state=42)\n",
    "    \n",
    "    # Fit and resample the training data\n",
    "    X_train_resampled, Y_train_resampled = smote_enn.fit_resample(X_train, Y_train)\n",
    "\n",
    "    # Save resampled data\n",
    "    np.save('data/X_train_resampled.npy', X_train_resampled)\n",
    "    np.save('data/Y_train_resampled.npy', Y_train_resampled)\n",
    "\n",
    "    print(\"Data resampled using SMOTEENN.\")\n",
    "    print(f\"Resampled Y distribution: {Counter(Y_train_resampled)}\")\n",
    "\n",
    "    # dump resampled data into resampled_data.csv\n",
    "    resampled_data = pd.DataFrame(X_train_resampled)\n",
    "    resampled_data['outcome'] = Y_train_resampled\n",
    "    resampled_data.to_csv('resampled_data.csv', index=False)\n",
    "\n",
    "    \n",
    "    return X_train_resampled, Y_train_resampled\n",
    "\n",
    "# Assuming X_train_scaled and Y_train are defined and preprocessed\n",
    "# X_train_resampled, Y_train_resampled = apply_smoteenn(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def feature_selection(X_train, Y_train, variance_threshold=0.01, k_best=20, correlation_threshold=0.1):\n",
    "    print(\"Starting feature selection...\")\n",
    "\n",
    "    # Variance Threshold\n",
    "    vt = VarianceThreshold(threshold=variance_threshold)\n",
    "    X_train_var = vt.fit_transform(X_train)\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = pd.DataFrame(X_train_var).corrwith(pd.Series(Y_train))\n",
    "    low_corr_features = correlation_matrix[correlation_matrix.abs() < correlation_threshold].index\n",
    "    # add these features in a npy file that conain all deleted features highly and low correlated\n",
    "    np.save('data/low_corr_features.npy', low_corr_features)\n",
    "\n",
    "    X_train_var = np.delete(X_train_var, low_corr_features, axis=1)\n",
    "\n",
    "    print(f\"Removed low correlation features: {low_corr_features.tolist()}\")\n",
    "\n",
    "    # Keep one feature from highly correlated features\n",
    "    corr_matrix = pd.DataFrame(X_train_var).corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "    np.save('data/high_corr_features.npy', to_drop)\n",
    "\n",
    "    # Retain only one feature from the highly correlated ones\n",
    "    X_train_var = np.delete(X_train_var, to_drop, axis=1)\n",
    "    print(f\"Removed highly correlated features: {to_drop}\")\n",
    "\n",
    "    # Mutual Information to select K best features\n",
    "    selector = SelectKBest(mutual_info_classif, k=k_best)\n",
    "    X_train_selected = selector.fit_transform(X_train_var, Y_train)\n",
    "\n",
    "    # Save the selected features\n",
    "    np.save('data/X_train_selected.npy', X_train_selected)\n",
    "\n",
    "    print(f\"Selected {k_best} best features using mutual information.\")\n",
    "    save_model_instance(selector, 'selector')\n",
    "    return X_train_selected, selector\n",
    "\n",
    "# X_train_selected, selector = feature_selection(X_train_resampled, Y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CODE FOR OULTLIER REMOVAL\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "# from sklearn.covariance import EllipticEnvelope\n",
    "# from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Example data: Replace this with your actual data\n",
    "# # df = pd.read_csv('your_data.csv')\n",
    "# # Assuming df is your dataframe with features and 'outcome' column as the target\n",
    "# X = df.drop('outcome', axis=1)\n",
    "# Y = df['outcome']\n",
    "\n",
    "# # Split into train and test sets\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "# # Apply one-hot encoding to categorical features\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# X_train_1 = encoder.fit_transform(X_train[['protocol_type']])\n",
    "# X_test_1 = encoder.transform(X_test[['protocol_type']])\n",
    "\n",
    "# X_train_2 = encoder.fit_transform(X_train[['service']])\n",
    "# X_test_2 = encoder.transform(X_test[['service']])\n",
    "\n",
    "# X_train_3 = encoder.fit_transform(X_train[['flag']])\n",
    "# X_test_3 = encoder.transform(X_test[['flag']])\n",
    "\n",
    "# # Concatenate encoded and numeric features\n",
    "# X_train_combined = np.concatenate([X_train_1, X_train_2, X_train_3, X_train.drop(['protocol_type', 'service', 'flag'], axis=1).values], axis=1)\n",
    "# X_test_combined = np.concatenate([X_test_1, X_test_2, X_test_3, X_test.drop(['protocol_type', 'service', 'flag'], axis=1).values], axis=1)\n",
    "\n",
    "# # Initialize RobustScaler and apply it to the training set\n",
    "# scaler = RobustScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "# X_test_scaled = scaler.transform(X_test_combined)\n",
    "\n",
    "# # Encode the target variable\n",
    "# label_encoder = LabelEncoder()\n",
    "# Y_train_encoded = label_encoder.fit_transform(Y_train)\n",
    "# Y_test_encoded = label_encoder.transform(Y_test)\n",
    "\n",
    "# # --------------------------------\n",
    "# # Step 1: Detect Outliers (Isolation Forest, LOF, Elliptic Envelope)\n",
    "# # --------------------------------\n",
    "\n",
    "# # Isolation Forest\n",
    "# iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "# iso_forest.fit(X_train_scaled)\n",
    "# train_iso_pred = iso_forest.predict(X_train_scaled)\n",
    "# test_iso_pred = iso_forest.predict(X_test_scaled)\n",
    "\n",
    "# # Local Outlier Factor (LOF)\n",
    "# lof = LocalOutlierFactor(contamination=0.1)\n",
    "# train_lof_pred = lof.fit_predict(X_train_scaled)\n",
    "\n",
    "# # Elliptic Envelope\n",
    "# elliptic = EllipticEnvelope(contamination=0.1)\n",
    "# elliptic.fit(X_train_scaled)\n",
    "# train_elliptic_pred = elliptic.predict(X_train_scaled)\n",
    "# test_elliptic_pred = elliptic.predict(X_test_scaled)\n",
    "\n",
    "# # Convert outliers (-1) to 1, inliers (1) to 0 for binary classification\n",
    "# train_iso_pred[train_iso_pred == 1] = 0\n",
    "# train_iso_pred[train_iso_pred == -1] = 1\n",
    "# test_iso_pred[test_iso_pred == 1] = 0\n",
    "# test_iso_pred[test_iso_pred == -1] = 1\n",
    "\n",
    "# train_lof_pred[train_lof_pred == 1] = 0\n",
    "# train_lof_pred[train_lof_pred == -1] = 1\n",
    "\n",
    "# train_elliptic_pred[train_elliptic_pred == 1] = 0\n",
    "# train_elliptic_pred[train_elliptic_pred == -1] = 1\n",
    "# test_elliptic_pred[test_elliptic_pred == 1] = 0\n",
    "# test_elliptic_pred[test_elliptic_pred == -1] = 1\n",
    "\n",
    "# # --------------------------------\n",
    "# # Step 2: Remove Outliers Based on Isolation Forest\n",
    "# # --------------------------------\n",
    "\n",
    "# # Filter out outliers (where prediction is 0)\n",
    "# X_train_cleaned = X_train_scaled[train_iso_pred == 0]\n",
    "# Y_train_cleaned = Y_train_encoded[train_iso_pred == 0]\n",
    "\n",
    "# X_test_cleaned = X_test_scaled[test_iso_pred == 0]\n",
    "# Y_test_cleaned = Y_test_encoded[test_iso_pred == 0]\n",
    "\n",
    "# # --------------------------------\n",
    "# # Step 3: Train Classifier After Removing Outliers\n",
    "# # --------------------------------\n",
    "\n",
    "# # Example classifier: Logistic Regression\n",
    "# clf = LogisticRegression(random_state=42)\n",
    "# clf.fit(X_train_cleaned, Y_train_cleaned)\n",
    "\n",
    "# # Make predictions on cleaned test set\n",
    "# predictions = clf.predict(X_test_cleaned)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print('Classification Report:')\n",
    "# print(classification_report(Y_test_cleaned, predictions, zero_division=0))\n",
    "\n",
    "# accuracy = accuracy_score(Y_test_cleaned, predictions)\n",
    "# print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# # --------------------------------\n",
    "# # Optional: Try LOF and Elliptic Envelope to Clean Data\n",
    "# # --------------------------------\n",
    "# # For LOF or Elliptic Envelope, follow a similar approach:\n",
    "# # - Use the predictions from the models (train_lof_pred or train_elliptic_pred)\n",
    "# # - Filter out the outliers and retrain the classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete pipeline function to execute all steps\n",
    "def complete_preprocessing_pipeline(df, target_column, categorical_columns):\n",
    "    # if resampled_data.csv exists dont apply smoteenn and mov to feature selection\n",
    "    if not os.path.exists('data/resampled_data.csv'):\n",
    "        print(\"Resampled data not found. Applying preprocessing steps...\")\n",
    "        create_directories()\n",
    "        X_train, X_test, Y_train, Y_test = load_and_split_data(df, target_column)\n",
    "        X_train_encoded, X_test_encoded, encoders = one_hot_encode(X_train, X_test, categorical_columns)\n",
    "        X_train_scaled, X_test_scaled, scaler = robust_scale(X_train_encoded, X_test_encoded)\n",
    "        # dump test data to csv\n",
    "        test_data = pd.DataFrame(X_test_scaled)\n",
    "        test_data['outcome'] = Y_test\n",
    "        test_data.to_csv('test_data.csv', index=False)\n",
    "        X_train_resampled, Y_train_resampled = apply_smoteenn(X_train_scaled, Y_train)\n",
    "    else:\n",
    "        print(\"Resampled data found. Skipping preprocessing steps...\")\n",
    "        resampled_data = pd.read_csv('data/resampled_data.csv')\n",
    "        X_train_resampled = resampled_data.drop('outcome', axis=1)\n",
    "        Y_train_resampled = resampled_data['outcome']\n",
    "        # apply label encoding to Y_train_resampled and then apply feature selection\n",
    "        label_encoder = LabelEncoder()\n",
    "        Y_train_resampled = label_encoder.fit_transform(Y_train_resampled)\n",
    "        #save this label encoder\n",
    "        save_model_instance(label_encoder, 'label_encoder')\n",
    "    X_train_selected, selector = feature_selection(X_train_resampled, Y_train_resampled)\n",
    "    # # dump the selected features to csv\n",
    "    # selected_data = pd.DataFrame(X_train_selected)\n",
    "    # selected_data['outcome'] = Y_train_resampled\n",
    "    # selected_data.to_csv('selected_data.csv', index=False)\n",
    "\n",
    "    # save_model_instance(encoders, 'encoders')\n",
    "    # save_model_instance(scaler, 'scaler')\n",
    "    # save_model_instance(selector, 'selector')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled data found. Skipping preprocessing steps...\n",
      "Saving model instance: label_encoder...\n"
     ]
    }
   ],
   "source": [
    "complete_preprocessing_pipeline(df, target_column='outcome', categorical_columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model instance: selector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcll/anaconda3/lib/python3.11/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator SelectKBest from version 1.4.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load encoders, scaler and selector\n",
    "def load_model_instance(filename):\n",
    "    print(f\"Loading model instance: {filename}...\")\n",
    "    return np.load(f'models/{filename}.npy', allow_pickle=True).item()\n",
    "\n",
    "selector = load_model_instance('selector')\n",
    "\n",
    "# load from instances\n",
    "# Train_data = pd.read_csv('resampled_data.csv')\n",
    "# Test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# # apply selector on train data\n",
    "\n",
    "# X_train_resampled = Train_data.drop('outcome', axis=1)\n",
    "# Y_train_resampled = Train_data['outcome']\n",
    "\n",
    "# X_train_selected = selector.transform(X_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # apply multinomial naive bayes on selected data\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# load selected data from selected_data.csv\n",
    "Train_data = pd.read_csv('data/selected_data.csv')\n",
    "Test_data = pd.read_csv('data/test_data.csv')\n",
    "\n",
    "X_train_selected = Train_data.drop('outcome', axis=1)\n",
    "Y_train_resampled = Train_data['outcome']\n",
    "\n",
    "# clf = MultinomialNB()\n",
    "# clf.fit(X_train_selected, Y_train_resampled)\n",
    "\n",
    "# # apply selector on test data\n",
    "# X_test = Test_data.drop('outcome', axis=1)\n",
    "# Y_test = Test_data['outcome']\n",
    "\n",
    "# X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# # make predictions\n",
    "# predictions = clf.predict(X_test_selected)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print('Classification Report:')\n",
    "# print(classification_report(Y_test, predictions, zero_division=0))\n",
    "\n",
    "# accuracy = accuracy_score(Y_test, predictions)\n",
    "# print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# # save the model\n",
    "# import joblib\n",
    "\n",
    "# joblib.dump(clf, 'multinomialNBmodel.pkl')\n",
    "# print(\"Model saved as model.pkl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and splitting the dataset...\n",
      "Data split into training and testing sets.\n"
     ]
    }
   ],
   "source": [
    "#This is done to reinstantiate Y_test\n",
    "X_train_temp, X_test_temp, Y_train_temp, Y_test = load_and_split_data(df, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_test = Test_data['outcome']\n",
    "# X_test = Test_data.drop('outcome', axis=1)\n",
    "X_test = np.load('data/X_test_scaled.npy')\n",
    "\n",
    "# read column name from data/selected_data.csv and save it as a list and select those columns from X_test\n",
    "selected_data = pd.read_csv('data/selected_data.csv')\n",
    "selected_columns = selected_data.columns.tolist()\n",
    "# remove outcome from selected_columns\n",
    "selected_columns.remove('outcome')\n",
    "\n",
    "# Get the indices of the selected columns\n",
    "selected_indices = [selected_data.columns.get_loc(col) for col in selected_columns]\n",
    "X_test_selected = X_test[:, selected_indices]\n",
    "\n",
    "#make dataframe for X_test_selected\n",
    "X_test_selected = pd.DataFrame(X_test_selected, columns=selected_columns)\n",
    "X_test_selected['outcome'] = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Converting selected data to numpy arrays...\n"
     ]
    }
   ],
   "source": [
    "#print type of X_test_selected and X_train_selected\n",
    "print(type(X_train_selected))\n",
    "print(type(X_test_selected))\n",
    "\n",
    "if isinstance(X_train_selected, pd.DataFrame) and isinstance(X_test_selected, pd.DataFrame):\n",
    "    print(\"Converting selected data to numpy arrays...\")\n",
    "    X_test_selected = X_test_selected[X_train_selected.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome\n",
      "DOS        78292\n",
      "normal     19456\n",
      "probing      822\n",
      "R2L          225\n",
      "U2R           10\n",
      "Name: count, dtype: int64\n",
      "outcome\n",
      "4    313002\n",
      "2    312997\n",
      "0    312966\n",
      "1    312253\n",
      "3    311917\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print class counts of Y_test and Y_train_resampled\n",
    "print(Y_test.value_counts())\n",
    "print(Y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model instance: label_encoder...\n",
      "outcome\n",
      "DOS        78292\n",
      "normal     19456\n",
      "probing      822\n",
      "R2L          225\n",
      "U2R           10\n",
      "Name: count, dtype: int64\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94     78292\n",
      "           1       0.01      0.02      0.01       225\n",
      "           2       0.00      1.00      0.00        10\n",
      "           3       0.50      0.00      0.00     19456\n",
      "           4       0.05      0.44      0.09       822\n",
      "\n",
      "    accuracy                           0.72     98805\n",
      "   macro avg       0.31      0.47      0.21     98805\n",
      "weighted avg       0.87      0.72      0.74     98805\n",
      "\n",
      "Model Accuracy: 0.7223\n"
     ]
    }
   ],
   "source": [
    "# apply vanila perceptron model for multiclass classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train_selected, Y_train_resampled)\n",
    "\n",
    "# Ensure X_test_selected and Y_test have the same number of samples\n",
    "X_test_selected = X_test_selected[:len(Y_test)]\n",
    "\n",
    "# make predictions\n",
    "# Encode Y_test using the same label encoder used for Y_train_resampled\n",
    "\n",
    "#load label encoder from models/label_encoder.npy\n",
    "label_encoder = load_model_instance('label_encoder')\n",
    "Y_test_encoded = label_encoder.fit_transform(Y_test)\n",
    "Y_test_encoded = pd.Series(Y_test_encoded)\n",
    "predictions = clf.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model\n",
    "print(Y_test.value_counts())\n",
    "print('Classification Report:')\n",
    "print(classification_report(Y_test_encoded, predictions, zero_division=0))\n",
    "\n",
    "accuracy = accuracy_score(Y_test_encoded, predictions)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix for perceptron model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(Y_test_encoded, predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as perceptronmodel.pkl.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# save the model\n",
    "joblib.dump(clf, 'perceptronmodel.pkl')\n",
    "print(\"Model saved as perceptronmodel.pkl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve, roc_auc_score, precision_recall_curve, auc\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get the probabilities for each class\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get the probabilities for each class\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m probs \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mdecision_function(X_test_selected)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Compute ROC curve and ROC area for each class\u001b[39;00m\n\u001b[1;32m      9\u001b[0m fpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "# plot ROC curve and find relevant metrics and do analysis on perceptron model\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "# Get the probabilities for each class\n",
    "\n",
    "# Get the probabilities for each class\n",
    "probs = clf.decision_function(X_test_selected)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = len(label_encoder.classes_)\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test_encoded, probs[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test_encoded.ravel(), probs.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label=f'micro-average ROC curve (area = {roc_auc[\"micro\"]:.2f})',\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "            label=f'macro-average ROC curve (area = {roc_auc[\"macro\"]:.2f})',\n",
    "            color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = ['aqua', 'darkorange', 'cornflowerblue', 'green', 'red']\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'ROC curve of class {label_encoder.classes_[i]} (area = {roc_auc[i]:.2f})')\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Perceptron Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Compute Precision-Recall curve and relevant metrics\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "pr_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(Y_test_encoded, probs[:, i], pos_label=i)\n",
    "    pr_auc[i] = auc(recall[i], precision[i])\n",
    "\n",
    "# Compute micro-average precision-recall curve and precision-recall area\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y_test_encoded.ravel(), probs.ravel())\n",
    "pr_auc[\"micro\"] = auc(recall[\"micro\"], precision[\"micro\"])\n",
    "\n",
    "# Compute macro-average precision-recall curve and precision-recall area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_recall = np.unique(np.concatenate([recall[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all precision-recall curves at this points\n",
    "mean_precision = np.zeros_like(all_recall)\n",
    "for i in range(n_classes):\n",
    "    mean_precision += np.interp(all_recall, recall[i], precision[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_precision /= n_classes\n",
    "\n",
    "recall[\"macro\"] = all_recall\n",
    "precision[\"macro\"] = mean_precision\n",
    "pr_auc[\"macro\"] = auc(recall[\"macro\"], precision[\"macro\"])\n",
    "\n",
    "# Plot all Precision-Recall curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.plot(recall[\"micro\"], precision[\"micro\"],\n",
    "            label=f'micro-average Precision-Recall curve (area = {pr_auc[\"micro\"]:.2f})',\n",
    "            color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(recall[\"macro\"], precision[\"macro\"],\n",
    "            label=f'macro-average Precision-Recall curve (area = {pr_auc[\"macro\"]:.2f})',\n",
    "            color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = ['aqua', 'darkorange', 'cornflowerblue', 'green', 'red']\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "             label=f'Precision-Recall curve of class {label_encoder.classes_[i]} (area = {pr_auc[i]:.2f})')\n",
    "    \n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve for Perceptron Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.89     78292\n",
      "           1       0.00      0.00      0.00       225\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.96      0.05      0.10     19456\n",
      "           4       0.00      0.00      0.00       822\n",
      "\n",
      "    accuracy                           0.80     98805\n",
      "   macro avg       0.35      0.21      0.20     98805\n",
      "weighted avg       0.82      0.80      0.72     98805\n",
      "\n",
      "Model Accuracy: 0.7982\n",
      "Model saved as decisiontreemodel.pkl.\n"
     ]
    }
   ],
   "source": [
    "# apply decision tree model for multiclasses\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_selected, Y_train_resampled)\n",
    "\n",
    "# make predictions\n",
    "predictions = clf.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Classification Report:')\n",
    "print(classification_report(Y_test_encoded, predictions, zero_division=0))\n",
    "\n",
    "accuracy = accuracy_score(Y_test_encoded, predictions)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# save the model\n",
    "joblib.dump(clf, 'decisiontreemodel.pkl')\n",
    "print(\"Model saved as decisiontreemodel.pkl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcll/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     78292\n",
      "           1       0.01      0.04      0.02       225\n",
      "           2       0.00      1.00      0.00        10\n",
      "           3       0.00      0.00      0.00     19456\n",
      "           4       0.00      0.00      0.00       822\n",
      "\n",
      "    accuracy                           0.79     98805\n",
      "   macro avg       0.19      0.41      0.20     98805\n",
      "weighted avg       0.75      0.79      0.77     98805\n",
      "\n",
      "Model Accuracy: 0.7860\n",
      "Model saved as softmaxregressionmodel.pkl.\n"
     ]
    }
   ],
   "source": [
    "# apply softmax regression model for multiclasses\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "clf.fit(X_train_selected, Y_train_resampled)\n",
    "\n",
    "# make predictions\n",
    "predictions = clf.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Classification Report:')\n",
    "print(classification_report(Y_test_encoded, predictions, zero_division=0))\n",
    "\n",
    "accuracy = accuracy_score(Y_test_encoded, predictions)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# save the model\n",
    "joblib.dump(clf, 'softmaxregressionmodel.pkl')\n",
    "print(\"Model saved as softmaxregressionmodel.pkl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply SVM model for multiclasses\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='rbf', C=1.0, gamma='scale', decision_function_shape='ovr', random_state=42)\n",
    "clf.fit(X_train_selected, Y_train_resampled)\n",
    "\n",
    "# make predictions\n",
    "predictions = clf.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Classification Report:')\n",
    "print(classification_report(Y_test, predictions, zero_division=0))\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# save the model\n",
    "joblib.dump(clf, 'svmmodel.pkl')\n",
    "print(\"Model saved as svmmodel.pkl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lazypredict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# apply lazy predict for multiclass classification\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlazypredict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSupervised\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyClassifier\n\u001b[1;32m      4\u001b[0m clf \u001b[38;5;241m=\u001b[39m LazyClassifier(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ignore_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, custom_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m models, predictions \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mfit(X_train_selected, X_test_selected, Y_train_resampled, Y_test)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lazypredict'"
     ]
    }
   ],
   "source": [
    "# apply lazy predict for multiclass classification\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train_selected, X_test_selected, Y_train_resampled, Y_test_encoded)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. feature report from claude also look for feature selection techniques from literature papers\n",
    "2. data vizualization\n",
    "3. why which preprocessing technique is used\n",
    "4. collect all results\n",
    "5. study results and plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
